<!DOCTYPE html><html><head><meta charset="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><link rel="shortcut icon" type="image/png" href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAAAAXNSR0IArs4c6QAABhRJREFUeAHtnNtrXHUQxyebTdNc2qRJqjEqUkVbL6hgwVv7pCCCf4CISPHBBxErvquo72Kl9sEHKSLiHyCIoE+trYIPKlUq3hBrjDbXNkmbZpM4ExtY2tjETDZ8fzPfgcNuLr/sfL/z2Tk5Z8+ZJvn0xIIw0jpQSaucwhcdIADJQSAABCC5A8nlswMQgOQOJJfPDkAAkjuQXD47AAFI7kBy+ewABCC5A8nlswMQgOQOJJfPDkAAkjuQXD47AAFI7kBy+ewABCC5A8nlswMQgOQOJJfPDkAAkjuQXD47AAFI7kBy+ewABCC5A8nlswMQgOQOJJfPDkAAkjuQXD47AAFI7kBy+ewABCC5A8nlswMQgOQOJJfPDkAAkjuQXD47QHIAqtH1d1cr8kBXu9yv20BrVfpamqW35d/Hvk3NsrW5Wc7MzcnwBd1m52Rktrb4ODhTk+MT03JMt/HafFibwgHQ1VyRR/s6ZW93h+zRot/R2SqVpqYrFrC3Ul2EYucyvzW/sCAnJmfkqIJwZHxKPh6elIm5OEA0RZkVfHfnZnn2um3yRH+3dCgEjYopLf4HQ+Ny6NSYfD15vlEvs2F/t2gAqvrGfvzqLi18z2KL3zDXLr6Q7SIOnRqVD/+akFqhI7eLBeDerW3yzq4BuXPL5o2u+2Wv9+3Z8/LMyUH58sy5y36G/o3G9coGKd+q7f3gLf1ybPcOiOKbTIPQ8rG8LL+SoqgO8EhPh7x727X633wLrMeDM7Py9Pd/yCejU7A51idWDK5P9nfJR3fdAF18M9bgtDwt3xKiCACe13/y3tN3frVy5cM5FMMtT8vX8kYPeABe3bFdDuy8RppWOJZHM9rytbwtf+SABuA5fQe9fONVyP6tmJvlbzpQAxYAO4v3xs39qL79r7xMh+lBDEgA2nQfelj3oS2F7PNXKqzpMD2mCy0gAXhJ95s3tW9C88qVj+kxXWgBB8B2/bRu//W9aD6tSz6my/QhBRwAL6hJ7YWdTVttQU2X6UMKKAAsmX0D3Uj+rHsupg/JdKRcZE+3XbSBe5p3PWgwfaYTJaAAeFjP9WeIh7bh6IQC4J4tbRnqL7v1o2yUgAJgV0crii8NzQNJJxQAPVWsQ6RGUYCkEwqAzqCHf5eChKQTCoDJQFfbXlr0+q/PAumEAmC0NlfvU9jnY0A6oQA4OTUTtuj1wpB0QgHwVYFX1dYXdrXPkXRCAfDZWBkXUq620P/1e0g6oQA4Oj4tdlVt5DB9phMloACwO+4OD46jeNOQPEwf0p2FUACY42/+PiLTQIdJ60mB6TJ9SAEHwGm9RfsAmEnrVTDTZfqQAg4AM+f1X0/Lz9MXkHxy52J6TBdaQAJwbn5B9untVbP6GCFMh+kxXWgBCYCZZAMZXvxxCM2vNeVjOkwPYsACYGYd1HvvX/vlb0TfVp2T5W86UAMaADPtFd1v7v/hT1nQUS0lheVreVv+yAEPgJn3lr6DntJ9aA1wH7pccS1Py9fyRo8iADAT3x+akMe++Q3+TKGd6bM8Ld8SohgAzEwbunDr8Z/kbT2etuldSGH5WF6WXynDIcy/oiaE1BecM4Lq3Vj782IBMMmcErb2wi+tLBqAJRH2yDmB9W6s/nkYAJYk108K3at34Nyul5qvNCl0ae1yj7Zv/06vVDqiH+FyUuhyDoF/z2YFP6jDGe7TbWlWcJ/OCu7Vu3RtVnCXzgqeuDgreEQ/qBmumxX8hZ69+1y3yLOCw3UAcB7h0ivqMBDOvQAJEYAARfRIIAAe9wKsJQABiuiRQAA87gVYSwACFNEjgQB43AuwlgAEKKJHAgHwuBdgLQEIUESPBALgcS/AWgIQoIgeCQTA416AtQQgQBE9EgiAx70AawlAgCJ6JBAAj3sB1hKAAEX0SCAAHvcCrCUAAYrokUAAPO4FWEsAAhTRI4EAeNwLsJYABCiiRwIB8LgXYC0BCFBEjwQC4HEvwFoCEKCIHgkEwONegLUEIEARPRIIgMe9AGsJQIAieiQQAI97AdYSgABF9EggAB73AqwlAAGK6JFAADzuBVhLAAIU0SOBAHjcC7CWAAQookfCP+kVjqIyPdfIAAAAAElFTkSuQmCC"/><link rel="preload" href="/myblog/component---src-layouts-index-js-9cceca90a718de9700cd.js" as="script"/><link rel="preload" href="/myblog/component---src-templates-blog-post-js-55b2a1a99d1ea213b953.js" as="script"/><link rel="preload" href="/myblog/path---posts-11-64142ec9824c2a7d7728.js" as="script"/><link rel="preload" href="/myblog/app-aaa42b203e53ba4b4de7.js" as="script"/><link rel="preload" href="/myblog/commons-68aad81503ae45628ade.js" as="script"/><script id="webpack-manifest">/*<![CDATA[*/window.webpackManifest={"231608221292675":"app-aaa42b203e53ba4b4de7.js","107818501498521":"component---src-templates-blog-post-js-55b2a1a99d1ea213b953.js","263791100135453":"component---src-pages-about-js-ff45d29fd778b5a39075.js","35783957827783":"component---src-pages-index-js-31d5d9c1c3bd56028ef0.js","60335399758886":"path----557518bd178906f8d58a.js","91246642375014":"path---posts-1-90166e225d03eda6390c.js","216243879586913":"path---posts-2-f92f30ac7d2d8cb243fe.js","142656853184902":"path---posts-10-660bb478f0dd0283a544.js","244307437753867":"path---posts-11-64142ec9824c2a7d7728.js","81878219163735":"path---posts-3-65ce2f5b9207722d610a.js","279941687692024":"path---posts-12-3f9ea3d4d59f59f6b1ee.js","12712639087417":"path---posts-13-72fdb549041284013dc5.js","130752015456929":"path---posts-7-f6ed77d92a2e941ca489.js","123118983598882":"path---posts-4-a4e48f0959469d2db888.js","4876863402267":"path---posts-5-1c348bc4f0bbbffb828e.js","106140644916941":"path---posts-6-654c88b5731d540ed597.js","93923592088315":"path---posts-8-7cce6f2a475c28aa3699.js","20147626466865":"path---posts-9-b20d26b952031219dcce.js","273950069227526":"path---about-a0e39f21c11f6a62c5ab.js","142629428675168":"path---index-e44882bdf4cd02f99a8d.js","114276838955818":"component---src-layouts-index-js-9cceca90a718de9700cd.js"}/*]]>*/</script><style type="text/css" data-styled-components="kNnBpQ iKSQLe djlcST ZZrCW cDUvTM iLZaUK jorVQO" data-styled-components-is-local="true">/* sc-component-id: sc-bdVaJa */

.kNnBpQ{height:100vh;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}
/* sc-component-id: sc-bwzfXH */

.djlcST{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;position:relative;}
/* sc-component-id: sc-htpNat */

.ZZrCW{position:absolute;top:0;left:0;right:0;bottom:0;}
/* sc-component-id: sc-bxivhb */

.iKSQLe{line-height:40px;padding:10px;background:#00bcd4;}.iKSQLe a{color:white;}
/* sc-component-id: sc-ifAKCX */

.jorVQO{background:#00bcd4;padding:28px;color:white;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}.jorVQO a{color:white;display:block;padding:0px;}
/* sc-component-id: sc-EHOje */

.cDUvTM{height:100%;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;padding-top:20px;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.cDUvTM .markdown-content{padding:20px;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}
/* sc-component-id: sc-bZQynM */

.iLZaUK{font-size:20px;text-align:center;font-weight:600px;}
</style><script>/*<![CDATA[*/!function(e,t,r){function n(){for(;d[0]&&"loaded"==d[0][f];)c=d.shift(),c[o]=!i.parentNode.insertBefore(c,i)}for(var s,a,c,d=[],i=e.scripts[0],o="onreadystatechange",f="readyState";s=r.shift();)a=e.createElement(t),"async"in i?(a.async=!1,e.head.appendChild(a)):i[f]?(d.push(a),a[o]=n):e.write("<"+t+' src="'+s+'" defer></'+t+">"),a.src=s}(document,"script",["/myblog/commons-68aad81503ae45628ade.js","/myblog/app-aaa42b203e53ba4b4de7.js","/myblog/path---posts-11-64142ec9824c2a7d7728.js","/myblog/component---src-templates-blog-post-js-55b2a1a99d1ea213b953.js","/myblog/component---src-layouts-index-js-9cceca90a718de9700cd.js"])/*]]>*/</script><style id="gatsby-inlined-css">code[class*=language-],pre[class*=language-]{color:#657b83;font-family:Consolas,Monaco,Andale Mono,Ubuntu Mono,monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-ms-hyphens:none;hyphens:none}code[class*=language-]::-moz-selection,code[class*=language-] ::-moz-selection,pre[class*=language-]::-moz-selection,pre[class*=language-] ::-moz-selection{background:#073642}code[class*=language-]::selection,code[class*=language-] ::selection,pre[class*=language-]::selection,pre[class*=language-] ::selection{background:#073642}pre[class*=language-]{padding:1em;margin:.5em 0;overflow:auto;border-radius:.3em}:not(pre)>code[class*=language-],pre[class*=language-]{background-color:#fdf6e3}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em}.token.cdata,.token.comment,.token.doctype,.token.prolog{color:#93a1a1}.token.punctuation{color:#586e75}.namespace{opacity:.7}.token.boolean,.token.constant,.token.deleted,.token.number,.token.property,.token.symbol,.token.tag{color:#268bd2}.token.attr-name,.token.builtin,.token.char,.token.inserted,.token.selector,.token.string,.token.url{color:#2aa198}.token.entity{color:#657b83;background:#eee8d5}.token.atrule,.token.attr-value,.token.keyword{color:#859900}.token.function{color:#b58900}.token.important,.token.regex,.token.variable{color:#cb4b16}.token.bold,.token.important{font-weight:700}.token.italic{font-style:italic}.token.entity{cursor:help}body{margin:0}a{text-decoration:none}*{box-sizing:border-box}</style></head><body><div id="___gatsby"><div class="sc-bdVaJa kNnBpQ" data-reactroot="" data-reactid="1" data-react-checksum="-602759959"><div class="sc-bxivhb iKSQLe" data-reactid="2"><a href="/myblog/" data-reactid="3">首页</a></div><div class="sc-bwzfXH djlcST" data-reactid="4"><div class="sc-htpNat ZZrCW" data-reactid="5"><div class="sc-EHOje cDUvTM" data-reactid="6"><!-- react-empty: 7 --><div class="sc-bZQynM iLZaUK" data-reactid="8">Keras 快速上手指南（下）</div><div class="markdown-content" data-reactid="9"><p>在之前的教程中，我们介绍了 Keras 网络的模型与网络层，并且通过许多示例展示了网络的搭建方式。大家都注意到了，在构建网络的过程中，损失函数、优化器、激活函数等都是需要自定义的网络配置项，下面我们对这些网络配置进行详细的介绍。</p>
<ol>
<li>
<p>损失函数
目标函数 objectives
目标函数，或称损失函数，是编译一个模型必须的两个参数之一：</p>
<div class="gatsby-highlight">
      <pre class="language-python"><code>model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string">'mean_squared_error'</span><span class="token punctuation">,</span> optimizer<span class="token operator">=</span><span class="token string">'sgd'</span><span class="token punctuation">)</span>
可以通过传递预定义目标函数名字指定目标函数，也可以传递一个 Theano<span class="token operator">/</span>TensroFlow 的符号函数作为目标函数，该函数对每个数据点应该只返回一个标量值，并以下列两个参数为参数：
</code></pre>
      </div>
</li>
</ol>
<p>y<em>true：真实的数据标签，Theano/TensorFlow 张量
y</em>pred：预测值，与 y_true 相同 shape 的 Theano/TensorFlow 张量
from keras import losses</p>
<p>model.compile(loss=losses.mean<em>squared</em>error, optimizer='sgd')
真实的优化目标函数是在各个数据点得到的损失函数值之和的均值。</p>
<p>预定义目标函数
mean<em>squared</em>error 或 mse：均方误差
mean<em>absolute</em>error 或 mae：平均绝对误差
mean<em>absolute</em>percentage<em>error 或 mape：平均绝对百分比误差
mean</em>squared<em>logarithmic</em>error 或 msle：均方误差对数
squared<em>hinge
hinge
binary</em>crossentropy：对数损失，logloss
logcosh
categorical<em>crossentropy：亦称作多类的对数损失，注意使用该目标函数时，需要将标签转化为形如 (nb</em>samples, nb<em>classes) 的二值序列
sparse</em>categorical<em>crossentrop：如上，但接受稀疏标签。注意，使用该函数时仍然需要你的标签与输出值的维度相同，你可能需要在标签数据上增加一个维度：np.expand</em>dims(y,-1)
kullback<em>leibler</em>divergence：从预测值概率分布 Q 到真值概率分布 P 的信息增益，用以度量两个分布的差异
poisson：即 (predictions - targets * log(predictions)) 的均值
cosine<em>proximity：即预测值与真实标签的余弦距离平均值的相反数
注意: 当使用”categorical</em>crossentropy”作为目标函数时，标签应该为多类模式，即 one-hot 编码的向量，而不是单个数值.。可以使用工具中的 to_categorical 函数完成该转换，示例如下：</p>
<p>from keras.utils.np<em>utils import to</em>categorical</p>
<p>categorical<em>labels = to</em>categorical(int<em>labels, num</em>classes=None)</p>
<div class="gatsby-highlight">
      <pre class="language-none"><code>2. 优化器
优化器是编译 Keras 模型必要的两个参数之一。
```python
from keras import optimizers

model = Sequential()
model.add(Dense(64, init='uniform', input_shape=(10,)))
model.add(Activation('tanh'))
model.add(Activation('softmax'))

sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(loss='mean_squared_error', optimizer=sgd)
可以在调用 model.compile() 之前初始化一个优化器对象，然后传入该函数（如上所示），也可以在调用 model.compile() 时传递一个预定义优化器名。在后者情形下，优化器的参数将使用默认值。

# 传递一个预定义优化器名
model.compile(loss='mean_squared_error', optimizer='sgd')
所有优化器都可用的参数
参数 clipnorm 和 clipvalue 是所有优化器都可以使用的参数，用于对梯度进行裁剪。示例如下：

from keras import optimizers

# 所有参数的梯度会被剪裁到最大范数为1.
sgd = optimizers.SGD(lr=0.01, clipnorm=1.)
from keras import optimizers

# 所有参数梯度会被剪裁到最大值为0.5，最小值为-0.5
sgd = optimizers.SGD(lr=0.01, clipvalue=0.5)
SGD
随机梯度下降法，支持动量参数，支持学习衰减率，支持 Nesterov 动量。

keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)
lr：大于 0 的浮点数，学习率
momentum：大于 0 的浮点数，动量参数
decay：大于 0 的浮点数，每次更新后的学习率衰减值
nesterov：布尔值，确定是否使用 Nesterov 动量
RMSprop
除学习率可调整外，建议保持优化器的其他默认参数不变。该优化器通常是面对递归神经网络时的一个良好选择。

keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-06)
lr：大于 0 的浮点数，学习率
rho：大于 0 的浮点数
epsilon：大于 0 的小浮点数，防止除 0 错误
Adam
该优化器的默认值来源于参考文献。

keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)
lr：大于 0 的浮点数，学习率
beta_1：浮点数， 0<beta<1，通常很接近 1
beta_2：浮点数， 0<beta<1，通常很接近 1
epsilon：大于 0的小浮点数，防止除 0 错误</code></pre>
      </div>
<ol start="3">
<li>
<p>激活函数
激活函数用于在模型中引入非线性。激活函数 </p>
<div class="gatsby-highlight">
      <pre class="language-python"><code>sigmoid
sigmoid​ 与 
tanh
tanh​ 曾经很流行，但现在很少用于视觉模型了，主要原因在于当输入的绝对值较大时，其导数接近于零，梯度的反向传播过程将被中断，出现梯度消散的现象。
</code></pre>
      </div>
</li>
</ol>
<p>1</p>
<p>ReLU
ReLU 是一个很好的替代：</p>
<p>2</p>
<p>相比于
sigmoid
sigmoid 与
tanh
tanh，它有两个优势：</p>
<p>没有饱和问题，大大缓解了梯度消散的现象，加快了收敛速度。
实现起来非常简单，加速了计算过程。
ReLU
ReLU 有一个缺陷，就是它可能会永远“死”掉：</p>
<p>假如有一组二维数据
X
X
(
x
1
,
x
2
)
(x1,x2) 分布在
x
1
:
[
0
,
1
]
,
x
2
:
[
0
,
1
]
x1:[0,1],x2:[0,1] 的区域内，有一组参数
W
W
(
w
1
,
w
2
)
(w1,w2) 对
X
X 做线性变换，并将结果输入到
ReLU
ReLU。
F
=
w
1
∗
x
1
+
w
2
∗
x
2
F=w1∗x1+w2∗x2 如果
w
1
=
w
2
=
−
1
w1=w2=−1，那么无论
X
X 如何取值，
F
F 必然小于等于零。那么
ReLU
ReLU 函数对
F
F 的导数将永远为零。这个
ReLU
ReLU 节点将永远不参与整个模型的学习过程。</p>
<p>造成上述现象的原因是
ReLU
ReLU 在负区间的导数为零，为了解决这一问题，人们发明了
Leaky ReLU
Leaky ReLU、
Parametric ReLU
Parametric ReLU、
Randomized ReLU
Randomized ReLU 等变体。他们的中心思想都是为
ReLU
ReLU 函数在负区间赋予一定的斜率，从而让其导数不为零（这里设斜率为
α
α）。</p>
<p>Leaky ReLU
Leaky ReLU 就是直接给
α
α 指定一个值，整个模型都用这个斜率：</p>
<p>3</p>
<p>Parametric ReLU
Parametric ReLU 将
α
α 作为一个参数，通过学习获取它的最优值。
Randomized ReLU
Randomized ReLU 为
α
α 规定一个区间，然后在区间内随机选取
α
α 的值。</p>
<p>4</p>
<p>在实践中，
Parametric ReLU
Parametric ReLU 和
Randomized ReLU
Randomized ReLU 都是可取的。</p>
<p>激活函数可以通过设置单独的激活层实现，也可以在构造层对象时通过传递 activation 参数实现。</p>
<p>from keras.layers import Activation, Dense</p>
<p>model.add(Dense(64))
model.add(Activation('tanh'))
等价于：</p>
<p>model.add(Dense(64, activation='tanh'))
也可以通过传递一个逐元素运算的 Theano/TensorFlow 函数来作为激活函数：</p>
<p>from keras import backend as K</p>
<p>def tanh(x):
return K.tanh(x)</p>
<p>model.add(Dense(64, activation=tanh))
model.add(Activation(tanh)
预定义激活函数
softmax：对输入数据的最后一维进行 softmax，输入数据应形如 (nb<em>samples, nb</em>timesteps, nb<em>dims) 或 (nb</em>samples, nb<em>dims)
elu
softplus
softsign
relu
tanh
sigmoid
hard</em>sigmoid
linear
高级激活函数
对于简单的 Theano/TensorFlow 不能表达的复杂激活函数，如含有可学习参数的激活函数，可通过高级激活函数实现，如 PReLU，LeakyReLU 等。下面我们详细介绍一下高级激活层。</p>
<div class="gatsby-highlight">
      <pre class="language-none"><code>4. 高级激活层
LeakyReLU 层
LeakyRelU 是修正线性单元(Rectified Linear Unit，ReLU)的特殊版本，当不激活时，LeakyReLU 仍然会有非零输出值，从而获得一个小梯度，避免 ReLU 可能出现的神经元“死亡”现象。
```python
keras.layers.advanced_activations.LeakyReLU(alpha=0.3)
alpha：大于 0 的浮点数，代表激活函数图像中第三象限线段的斜率
该层输入 shape 任意，当使用该层为模型首层时需指定 input_shape 参数，输出 shape 与输入相同。

PReLU 层
该层为参数化的 ReLU(Parametric ReLU)，表达式是：
f
(
x
)
=
{
α
∗
x
,
x
<
0
x
,
x
≥
0
f(x)={α∗x,x<0x,x≥0，此处的 
α
α 为一个与 xshape 相同的可学习的参数向量。

keras.layers.advanced_activations.PReLU(shared_axes=None)
shared_axes：该参数指定的轴将共享同一组科学系参数，例如假如输入特征图是从 2D 卷积过来的，具有形如 (batch, height, width, channels) 这样的 shape，则或许你会希望在空域共享参数，这样每个 filter 就只有一组参数，设定 shared_axes=[1,2] 可完成该目标
ELU 层
ELU 层是指数线性单元(Exponential Linera Unit)，表达式为： 该层为参数化的 ReLU(Parametric ReLU)，表达式是：
f
(
x
)
=
{
α
∗
(
exp
(
x
)
−
1
)
,
x
<
0
x
,
x
≥
0
f(x)={α∗(exp⁡(x)−1),x<0x,x≥0。

keras.layers.advanced_activations.ELU(alpha=1.0)
alpha：控制负因子的参数
该层输入 shape 任意，当使用该层为模型首层时需指定 input_shape 参数，输出 shape 与输入相同。

ThresholdedReLU 层
该层是带有门限的 ReLU，表达式是：
f
(
x
)
=
{
x
,
x
>
θ
0
,
otherwise
f(x)={x,x>θ0,otherwise。

keras.layers.advanced_activations.ThresholdedReLU(theta=1.0)
theata：大或等于 0 的浮点数，激活门限位置
该层输入 shape 任意，当使用该层为模型首层时需指定 input_shape 参数，输出 shape 与输入相同。</code></pre>
      </div>
<ol start="5">
<li>
<p>数据预处理
填充序列
将长为 nb<em>samples 的序列（标量序列）转化为形如 (nb</em>samples,nb<em>timesteps) 的 2D numpy array。如果提供了参数 maxlen，nb</em>timesteps=maxlen，否则其值为最长序列的长度。其他短于该长度的序列都会在后部填充 0以达到该长度。长于 nb_timesteps 的序列将会被截断，以使其匹配目标长度。padding 和截断发生的位置分别取决于 padding 和 truncating。</p>
<div class="gatsby-highlight">
      <pre class="language-python"><code>keras<span class="token punctuation">.</span>preprocessing<span class="token punctuation">.</span>sequence<span class="token punctuation">.</span>pad_sequences<span class="token punctuation">(</span>sequences<span class="token punctuation">,</span> maxlen<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'int32'</span><span class="token punctuation">,</span>
padding<span class="token operator">=</span><span class="token string">'pre'</span><span class="token punctuation">,</span> truncating<span class="token operator">=</span><span class="token string">'pre'</span><span class="token punctuation">,</span> value<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
sequences：浮点数或整数构成的两层嵌套列表
maxlen：<span class="token boolean">None</span> 或整数，为序列的最大长度。大于此长度的序列将被截短，小于此长度的序列将在后部填 <span class="token number">0</span>
dtype：返回的 numpy array 的数据类型
padding：“pre”或“post”，确定当需要补 <span class="token number">0</span> 时，在序列的起始还是结尾补
truncating：“pre”或“post”，确定当需要截断序列时，从起始还是结尾截断
value：浮点数，此值将在填充时代替默认的填充值 <span class="token number">0</span>
返回值返回形如 <span class="token punctuation">(</span>nb_samples<span class="token punctuation">,</span>nb_timesteps<span class="token punctuation">)</span> 的 <span class="token number">2D</span> 张量。
</code></pre>
      </div>
</li>
</ol>
<p>句子分割
本函数将一个句子拆分成单词构成的列表。</p>
<p>keras.preprocessing.text.text<em>to</em>word<em>sequence(text, filters=base</em>filter(), lower=True, split=" ")
text：字符串，待处理的文本
filters：需要滤除的字符的列表或连接形成的字符串，例如标点符号。默认值为base_filter()，包含标点符号，制表符和换行符等
lower：布尔值，是否将序列设为小写形式
split：字符串，单词的分隔符，如空格
返回值为字符串列表。</p>
<p>one-hot 编码
本函数将一段文本编码为 one-hot 形式的码，即仅记录词在词典中的下标。</p>
<p>从定义上，当字典长为 n 时，每个单词应形成一个长为 n 的向量，其中仅有单词本身在字典中下标的位置为 1，其余均为 0，这称为 one-hot。</p>
<p>为了方便起见，函数在这里仅把“1”的位置，即字典中词的下标记录下来。</p>
<p>keras.preprocessing.text.one<em>hot(text, n, filters=base</em>filter(), lower=True, split=" ")
text：字符串，待处理的文本
n：整数，字典长度
filters：需要滤除的字符的列表或连接形成的字符串，例如标点符号。默认值为base_filter()，包含标点符号，制表符和换行符等
lower：布尔值，是否将序列设为小写形式
split：字符串，单词的分隔符，如空格
返回值为整数列表，每个整数是
<a href="">
1
,
n
</a> 之间的值，代表一个单词（不保证唯一性，即如果词典长度不够，不同的单词可能会被编为同一个码）。</p>
<p>分词器
Tokenizer 是一个用于向量化文本，或将文本转换为序列（即单词在字典中的下标构成的列表，从 1 算起）的类。</p>
<p>keras.preprocessing.text.Tokenizer(nb<em>words=None, filters=base</em>filter(), lower=True, split=" ")
nb<em>words：None 或整数，处理的最大单词数量。若被设置为整数，则分词器将被限制为处理数据集中最常见的 nb</em>words-1 个单词
filters：需要滤除的字符的列表或连接形成的字符串，例如标点符号。默认值为base_filter()，包含标点符号，制表符和换行符等
lower：布尔值，是否将序列设为小写形式
split：字符串，单词的分隔符，如空格
类方法：</p>
<p>fit<em>on</em>texts(texts)
texts：要用以训练的文本列表
texts<em>to</em>sequences(texts)
texts：待转为序列的文本列表
返回值：序列的列表，列表中每个序列对应于一段输入文本
texts<em>to</em>sequences<em>generator(texts)
本函数是 texts</em>to<em>sequences 的生成器函数版
texts：待转为序列的文本列表
返回值：每次调用返回对应于一段输入文本的序列
texts</em>to<em>matrix(texts, mode)：
texts：待向量化的文本列表
mode：“binary”、“count”、“tfidf”、“freq”之一，默认为“binary”
返回值：形如 (len(texts), nb</em>words) 的 numpy array
fit<em>on</em>sequences(sequences):
sequences：要用以训练的序列列表
sequences<em>to</em>matrix(sequences):
sequences：待向量化的序列列表
mode：“binary”、“count”、“tfidf”、“freq”之一，默认为“binary”
返回值：形如 (len(sequences), nb_words) 的 numpy array
属性：</p>
<p>word<em>counts：字典，将单词（字符串）映射为它们在训练期间出现的次数。仅在调用 fit</em>on<em>texts 之后设置。
word</em>docs：字典，将单词（字符串）映射为它们在训练期间所出现的文档或文本的数量。仅在调用 fit<em>on</em>texts 之后设置。
word<em>index：字典，将单词（字符串）映射为它们的排名或者索引。仅在调用 fit</em>on<em>texts 之后设置。
document</em>count：整数。分词器被训练的文档（文本或者序列）数量。仅在调用 fit<em>on</em>texts 或 fit<em>on</em>sequences 之后设置。</p>
<div class="gatsby-highlight">
      <pre class="language-none"><code></code></pre>
      </div></div><div class="sc-ifAKCX jorVQO" data-reactid="10"><div data-reactid="11"><a href="/myblog/posts/10" data-reactid="12">Prev</a></div><div data-reactid="13"><a href="/myblog/posts/12" data-reactid="14">Next</a></div></div></div></div></div></div></div></body></html>